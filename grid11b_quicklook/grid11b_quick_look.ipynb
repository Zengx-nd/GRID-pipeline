{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 输出文件 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, struct\n",
    "\n",
    "output_base_path = '/lime/GRID/quick_look/GRID-11B/quick_look'\n",
    "\n",
    "# output_base_path = r'quick_look'\n",
    "if not os.path.exists(output_base_path):\n",
    "    os.mkdir(output_base_path)\n",
    "\n",
    "output_lc_dir = os.path.join(output_base_path, 'output_lightcurve')\n",
    "output_lc_zm_dir = os.path.join(output_base_path, 'output_lightcurve', 'zoomed')\n",
    "output_spec_dir = os.path.join(output_base_path, 'output_spectrum')\n",
    "output_temp_dir = os.path.join(output_base_path, 'output_temperature')\n",
    "output_cur_dir = os.path.join(output_base_path, 'output_current')\n",
    "output_vol_dir = os.path.join(output_base_path, 'output_voltage')\n",
    "output_log_file = os.path.join(output_base_path, 'log.txt')\n",
    "output_lc_csv_dir = os.path.join(output_base_path, 'output_lc_csv')\n",
    "output_consecutive_dir = os.path.join(output_base_path, 'consecutive_periods')\n",
    "\n",
    "if not os.path.exists(output_lc_dir):\n",
    "    os.makedirs(output_lc_dir)\n",
    "if not os.path.exists(output_lc_zm_dir):\n",
    "    os.makedirs(output_lc_zm_dir)\n",
    "if not os.path.exists(output_spec_dir):\n",
    "    os.makedirs(output_spec_dir)\n",
    "if not os.path.exists(output_temp_dir):\n",
    "    os.makedirs(output_temp_dir)\n",
    "if not os.path.exists(output_cur_dir):\n",
    "    os.makedirs(output_cur_dir)\n",
    "if not os.path.exists(output_vol_dir):\n",
    "    os.makedirs(output_vol_dir)\n",
    "if not os.path.exists(output_log_file):\n",
    "    with open(output_log_file, 'w') as f:\n",
    "        f.write('')\n",
    "if not os.path.exists(output_lc_csv_dir):\n",
    "    os.makedirs(output_lc_csv_dir)\n",
    "if not os.path.exists(output_consecutive_dir):\n",
    "    os.makedirs(output_consecutive_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 待解析文件 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_file_list = []\n",
    "hk_file_list = []\n",
    "iv_file_list = []\n",
    "log_file_list = []\n",
    "raw_data_path = '/lime/GRID/quick_look/GRID-11B'\n",
    "for root, dirs, files in os.walk('/lime/GRID/quick_look/GRID-11B/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.raw') and '_sci_' in file:\n",
    "            sci_file_list.append(os.path.join(root, file))\n",
    "        if file.endswith('.dat') and '_hk_' in file:\n",
    "            hk_file_list.append(os.path.join(root, file))\n",
    "        if file.endswith('.raw') and '_iv_' in file:\n",
    "            iv_file_list.append(os.path.join(root, file))\n",
    "        if file.endswith('.txt') and '_log_' in file:\n",
    "            log_file_list.append(os.path.join(root, file))\n",
    "\n",
    "# sci_file_path = os.path.join(raw_data_path, '200322030_JL1PT02A03_20241117230547_tiange-splited/000_sci_162.raw')\n",
    "# sci_file_list.append(sci_file_path)\n",
    "print('sci_file_num = ', len(sci_file_list))\n",
    "print('hk_file_num = ', len(hk_file_list))\n",
    "print('iv_file_num = ', len(iv_file_list))\n",
    "print('log_file_num = ', len(log_file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 能谱曲线 分bin 规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# bin edges for long and short spectrums\n",
    "bin_edges_long = [46,102,149,153,158,\n",
    "                  163,172,177,185,191,\n",
    "                  203,211,219,231,235,\n",
    "                  241,250,265,277,284,\n",
    "                  301,308,310,321,330,\n",
    "                  332,337,342,347,352,\n",
    "                  358,361,362,366,370,\n",
    "                  373,378,380,385,388,\n",
    "                  394,397,402,407,411,\n",
    "                  424,428,433,442,455,\n",
    "                  468,479,490,515,543,\n",
    "                  558,606,651,739,851,\n",
    "                  903,1031,1222,1323,1485,\n",
    "                  1602,1793,1863,1959,2236,\n",
    "                  2596,2822,2970,3086,3238,\n",
    "                  3501,3818,4253,5144,11062,\n",
    "                  13000,15000,np.inf]\n",
    "\n",
    "bin_edges_short = [32,149,271,367,465,1528,2886,5259,np.inf]\n",
    "\n",
    "# 计算 bin宽\n",
    "bin_width_long = []\n",
    "for i in range(len(bin_edges_long)-1):\n",
    "    bin_width_long.append(bin_edges_long[i+1] - bin_edges_long[i])\n",
    "bin_width_long = np.array(bin_width_long)\n",
    "bin_width_short = []\n",
    "for i in range(len(bin_edges_short)-1):\n",
    "    bin_width_short.append(bin_edges_short[i+1] - bin_edges_short[i])\n",
    "bin_width_short = np.array(bin_width_short)\n",
    "\n",
    "# 计算 bin中点\n",
    "bin_middle_long = []\n",
    "for i in range(len(bin_edges_long)-1):\n",
    "    bin_middle_long.append((bin_edges_long[i] + bin_edges_long[i+1]) / 2 - 0.5)\n",
    "bin_middle_short = []\n",
    "for i in range(len(bin_edges_short)-1):\n",
    "    bin_middle_short.append((bin_edges_short[i] + bin_edges_short[i+1]) / 2 - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCI 高通量模式 (SPEC)  特征量模式 (TTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在 .raw 文件 寻找所有 TTE 和 SPEC 模式 pattern ， 返回 TTE, SPEC 包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_file = sci_file_list[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> Processing SCI File\n",
      ">> Read File\n",
      "<< Read File\n",
      ">> Find TTE\n",
      "<< Find TTE\n",
      ">> Find SPEC\n",
      "<< Find SPEC\n",
      "Found 56916 SPEC packs\n",
      "Found 1042939 TTE packs\n"
     ]
    }
   ],
   "source": [
    "def scan_sci_from_file(filename):\n",
    "    # 能谱模式\n",
    "    pattern1_spec = re.compile(b'\\\\x3f\\\\x3f\\\\x44\\\\xcc')\n",
    "    pattern2_spec = re.compile(b'\\\\x33\\\\xff\\\\xcc\\\\x44')\n",
    "    \n",
    "    # 特征量模式\n",
    "    pattern1_ttl = re.compile(b'\\\\x1C\\\\x1C\\\\x22\\\\x88')\n",
    "    pattern2_ttl = re.compile(b'\\\\xCC\\\\x11\\\\x88\\\\x22')\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        print('>> Read File')\n",
    "        data = f.read()\n",
    "        print('<< Read File')\n",
    "\n",
    "        print('>> Find TTE')\n",
    "        sci_packs_tte = []\n",
    "        start_indices = [m.start() for m in pattern1_ttl.finditer(data)]\n",
    "        for i in range(len(start_indices)):\n",
    "            if start_indices[i] >= len(data) - 528:\n",
    "                continue\n",
    "            if pattern2_ttl.match(data[start_indices[i]+524:start_indices[i]+528]):\n",
    "                sci_packs_tte.append(data[start_indices[i]:start_indices[i]+528])\n",
    "        print('<< Find TTE')\n",
    "\n",
    "        print('>> Find SPEC')\n",
    "        sci_packs_spec = []\n",
    "        start_indices = [m.start() for m in pattern1_spec.finditer(data)]\n",
    "        for i in range(len(start_indices)):\n",
    "            if start_indices[i] >= len(data) - 528:\n",
    "                continue\n",
    "            if pattern2_spec.match(data[start_indices[i]+524:start_indices[i]+528]):\n",
    "                sci_packs_spec.append(data[start_indices[i]:start_indices[i]+528])\n",
    "        print('<< Find SPEC')\n",
    "\n",
    "        print('Found %d SPEC packs' % len(sci_packs_spec))\n",
    "        print('Found %d TTE packs' % len(sci_packs_tte))\n",
    "        \n",
    "    return sci_packs_tte, sci_packs_spec\n",
    "\n",
    "print('==============> Processing SCI File')\n",
    "sci_packs_tte, sci_packs_spec = scan_sci_from_file(sci_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在 每秒的 SPEC包 中寻找特征信息：UTC 通道号 82个长光谱 8个短光谱（20*8）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sci_spec(pack):\n",
    "    utc = struct.unpack('>I', pack[4:8])[0]\n",
    "    channel = struct.unpack('>H', pack[20:22])[0]\n",
    "    event_num = struct.unpack('>I', pack[22:26])[0]\n",
    "\n",
    "    spectrum_long = []\n",
    "    spectrum_shorts = []\n",
    "\n",
    "    for i in range(82):\n",
    "        spectrum_long.append(struct.unpack('>H', pack[38+2*i:38+2*i+2])[0])\n",
    "    for i in range(20):\n",
    "        spectrum_short = []\n",
    "        for j in range(8):\n",
    "            spectrum_short.append(struct.unpack('>H', pack[202+16*i+2*j:202+16*i+2*j+2])[0])\n",
    "        spectrum_shorts.append(spectrum_short)\n",
    "    \n",
    "    return utc, channel, event_num, spectrum_long, spectrum_shorts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查是否存在 重复包 (utc, channel, event_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('>> Duplicate Check')\n",
    "\n",
    "# duplicate_checker_set = set()\n",
    "# counter = 0\n",
    "# for pack in packs:\n",
    "#     utc, channel, event_num, spectrum_long, spectrum_shorts = parse_sci(pack)\n",
    "#     if (utc, channel, event_num) in duplicate_checker_set:\n",
    "#         continue\n",
    "#     duplicate_checker_set.add((utc, channel, event_num))\n",
    "#     counter += 1\n",
    "\n",
    "# print('<< Duplicate Check')\n",
    "# print('非重复包数量 = ', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算SPEC模式的： 1.cps 2.长周期光谱 3.短周期光谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps_spec = [{}, {}, {}, {}]\n",
    "total_spectrum_long = np.zeros((4, 82), dtype=float)\n",
    "total_spectrum_short = np.zeros((4, 8), dtype=float)\n",
    "\n",
    "for pack in sci_packs_spec:\n",
    "    utc, channel, event_num, spectrum_long, spectrum_shorts = parse_sci_spec(pack)\n",
    "    \n",
    "    spec_count_sum = 0\n",
    "    for i in range(82):\n",
    "        spec_count_sum += spectrum_long[i]\n",
    "    if utc in cps_spec[channel]:\n",
    "        cps_spec[channel][utc] += spec_count_sum\n",
    "    else:\n",
    "        cps_spec[channel][utc] = spec_count_sum\n",
    "    \n",
    "    for spec_ch in range(82):\n",
    "        total_spectrum_long[channel][spec_ch] += spectrum_long[spec_ch]\n",
    "    for spec_num in range(20):\n",
    "        for spec_ch in range(8):\n",
    "            total_spectrum_short[channel][spec_ch] += spectrum_shorts[spec_num][spec_ch]\n",
    "\n",
    "for channel in range(4):\n",
    "    for spec_ch in range(82):\n",
    "        total_spectrum_long[channel][spec_ch] /= bin_width_long[spec_ch]\n",
    "    for spec_ch in range(8):\n",
    "        total_spectrum_short[channel][spec_ch] /= bin_width_short[spec_ch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在每秒的 TTE包 中寻找粒子信息：UTC 通道号 41个事件的触发时间戳、波形峰值等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sci_tte(pack):\n",
    "    utc = struct.unpack('>I', pack[4:8])[0]\n",
    "    # 秒脉冲时间戳  总共 8 个字节 \n",
    "    pps_stamp = struct.unpack('>Q', pack[12:20])[0]\n",
    "    channel = struct.unpack('>H', pack[20:22])[0]\n",
    "    event_num = struct.unpack('>I', pack[22:26])[0]\n",
    "\n",
    "    particle_info = []\n",
    "\n",
    "    for i in range(41):\n",
    "        trig_stamp = struct.unpack('>I', pack[28+12*i:28+12*i+4])[0]\n",
    "        wave_max = struct.unpack('>H', pack[32+12*i:32+12*i+2])[0]\n",
    "        wave_base = struct.unpack('>H', pack[34+12*i:34+12*i+2])[0]\n",
    "        wave_sum = struct.unpack('>I', pack[36+12*i:36+12*i+4])[0]\n",
    "        \n",
    "        particle_info.append((trig_stamp, wave_max, wave_base, wave_sum))\n",
    "    \n",
    "\n",
    "    particle_num = struct.unpack('>H', pack[26: 26+2])[0]\n",
    "\n",
    "    return utc, pps_stamp, channel, event_num, particle_num, particle_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算TTE模式的： cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps_tte = [{}, {}, {}, {}]\n",
    "# UTC = []\n",
    "# CHANNEL = []\n",
    "# EVNUM = []\n",
    "# TRIG_STAMP = []\n",
    "# WAVE_MAX = []\n",
    "# WAVE_BASE = []\n",
    "# WAVE_SUM = []\n",
    "# all_41 = True\n",
    "\n",
    "for pack in sci_packs_tte:\n",
    "    utc, pps_stamp, channel, event_num, particle_num, info= parse_sci_tte(pack)\n",
    "    if utc not in cps_tte[channel]:\n",
    "        cps_tte[channel][utc] = 0\n",
    "    cps_tte[channel][utc] += particle_num\n",
    "\n",
    "    # UTC.append(utc)\n",
    "    # CHANNEL.append(channel)\n",
    "    # EVNUM.append(event_num)\n",
    "    \n",
    "    # if particle_num != 41:\n",
    "    #     all_41 = False\n",
    "    # for particle in info:\n",
    "        # TRIG_STAMP.append(particle[0])\n",
    "        # WAVE_MAX.append(particle[1])\n",
    "        # WAVE_BASE.append(particle[2])\n",
    "        # WAVE_SUM.append(particle[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出 SPEC模式 和 TTE模式 的 cps 数据为 .CSV 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732816151 1732893427\n",
      "2024-11-28 17:49:11+00:00 2024-11-29 15:17:07+00:00\n",
      "202411281749_202411291517 \n",
      " /lime/GRID/quick_look/GRID-11B/quick_look/output_lc_csv/202411281749_202411291517_009_sci_174_spec.csv \n",
      " /lime/GRID/quick_look/GRID-11B/quick_look/output_lightcurve/009_sci_174.raw.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "fontdict = {'family':'WenQuanYi Zen Hei', 'size':16, 'color':'b'}\n",
    "plt.clf()\n",
    "\n",
    "utc_min = min([min(cps_spec[channel].keys()) for channel in range(4)])\n",
    "utc_max = max([max(cps_spec[channel].keys()) for channel in range(4)])\n",
    "date_min = datetime.datetime.fromtimestamp(utc_min, tz=datetime.timezone.utc)\n",
    "date_max = datetime.datetime.fromtimestamp(utc_max, tz=datetime.timezone.utc)\n",
    "\n",
    "print(utc_min, utc_max)\n",
    "print(date_min, date_max)\n",
    "utc_in_filename = date_min.strftime('%Y%m%d%H%M') + '_' + date_max.strftime('%Y%m%d%H%M')\n",
    "spec_csv_file_path = os.path.join(output_lc_csv_dir, utc_in_filename + '_' + sci_file.split('/')[-1][:-4] + '_spec.csv')\n",
    "tte_csv_file_path = os.path.join(output_lc_csv_dir, utc_in_filename + '_' + sci_file.split('/')[-1][:-4] + '_tte.csv')\n",
    "\n",
    "cps_figure_path = os.path.join(output_lc_dir, sci_file.split('/')[-1] + '.png')\n",
    "print(utc_in_filename, '\\n', spec_csv_file_path, '\\n', cps_figure_path)\n",
    "\n",
    "all_utc = set()\n",
    "with open(spec_csv_file_path, 'w') as f:\n",
    "    f.write('UTC,Channel,Counts\\n')\n",
    "    for channel in range(4):\n",
    "        all_utc.update(cps_spec[channel].keys())\n",
    "    all_utc = sorted(list(all_utc))\n",
    "    for utc in all_utc:\n",
    "        for channel in range(4):\n",
    "            if utc in cps_spec[channel]:\n",
    "                f.write('%d,%d,%d\\n' % (utc, channel, cps_spec[channel][utc]))\n",
    "            else:\n",
    "                f.write('%d,%d,%d\\n' % (utc, channel, 0))\n",
    "\n",
    "all_utc = set()\n",
    "with open(tte_csv_file_path, 'w') as f:\n",
    "    f.write('UTC,Channel,Counts\\n')\n",
    "    for channel in range(4):\n",
    "        all_utc.update(cps_tte[channel].keys())\n",
    "    all_utc = sorted(list(all_utc))\n",
    "    for utc in all_utc:\n",
    "        for channel in range(4):\n",
    "            if utc in cps_tte[channel]:\n",
    "                f.write('%d,%d,%d\\n' % (utc, channel, cps_tte[channel][utc]))\n",
    "            else:\n",
    "                f.write('%d,%d,%d\\n' % (utc, channel, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在 时间戳序列 中寻找 连续的时间段， 视为 模式启用 的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制 高通量持续时间 分布直方图\n",
    "def plot_time_periods(periods):\n",
    "    durations = [(end - start).total_seconds() for start, end in periods]\n",
    "    \n",
    "    print(durations)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(range(len(periods)), durations, tick_label=None)\n",
    "    \n",
    "    plt.title('高通量模式持续时间', fontdict=fontdict)\n",
    "    plt.xlabel('开启高通量模式的次数', fontdict=fontdict)\n",
    "    plt.ylabel('持续时间（s）', fontdict=fontdict)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_log_path = os.path.join(output_consecutive_dir, utc_in_filename + '_SPEC_TIME.txt')\n",
    "tte_log_path = os.path.join(output_consecutive_dir, utc_in_filename + '_TTE_TIME.txt')\n",
    "\n",
    "# 寻找 连续时间段， 要求 连续的长度 不小于 3\n",
    "def find_consecutive_time_periods(time_series, min_length=3):\n",
    "    time_series = [datetime.datetime.fromtimestamp(time, tz=datetime.timezone.utc) for time in time_series]\n",
    "    \n",
    "    consecutive_periods = []\n",
    "    current_start = time_series[0]\n",
    "    current_length = 1\n",
    "\n",
    "    for i in range(1, len(time_series)):\n",
    "        if time_series[i] == time_series[i-1]:\n",
    "            continue\n",
    "        if time_series[i] - time_series[i-1] == datetime.timedelta(seconds=1):\n",
    "            current_length += 1\n",
    "        else:\n",
    "            if current_length >= min_length:\n",
    "                consecutive_periods.append((current_start, time_series[i-1]))\n",
    "            current_start = time_series[i]\n",
    "            current_length = 1\n",
    "\n",
    "    if current_length >= min_length:\n",
    "        consecutive_periods.append((current_start, time_series[-1]))\n",
    "    \n",
    "    return consecutive_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将 模式启用的时间 保存为 .TXT 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_consecutive_periods(consecutive_periods, mode, base_time):\n",
    "    if mode == 'spec':\n",
    "        file = open(spec_log_path, 'w')\n",
    "        print(f'\\n\\nGRID-11B {date_min} 至 {date_max} 高通量模式启用 的时间段\\n\\nNumber of Consecutive Periods = ', len(consecutive_periods), '\\n', file=file)\n",
    "        print('                  起始时间                     结束时间                 持续时间                 相对零点起始时间\\n', file=file)\n",
    "    \n",
    "    if mode == 'tte':\n",
    "        file = open(tte_log_path, 'w')\n",
    "        print(f'\\n\\nGRID-11B {date_min} 至 {date_max} 特征量模式启用 的时间段\\n\\nNumber of Consecutive Periods = ', len(consecutive_periods), '\\n', file=file)\n",
    "        print('                  起始时间                     结束时间                 持续时间                 相对零点起始时间\\n', file=file)\n",
    "\n",
    "    index = 1\n",
    "    for start_time, end_time in consecutive_periods:\n",
    "        print(f\"{index}\\t:  {start_time.strftime('%m-%d %H:%M:%S')}  ==>  \\\n",
    "            {end_time.strftime('%m-%d %H:%M:%S')}      :      {end_time-start_time}           :              \\\n",
    "            {start_time-datetime.datetime.fromtimestamp(base_time, tz=datetime.timezone.utc)}\", file=file)\n",
    "        index += 1\n",
    "    file.close()\n",
    "    # plot_time_periods(consecutive_periods)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置通道， 绘制该通道的 光变曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:00'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "# spec\n",
    "utc_list = list(cps_spec[channel].keys())\n",
    "for i in range(len(utc_list)):\n",
    "    if utc_list[i] < 1e8:\n",
    "        utc_list[i] = np.nan\n",
    "\n",
    "consecutive_periods = find_consecutive_time_periods(utc_list)\n",
    "save_consecutive_periods(consecutive_periods, mode='spec', base_time=utc_list[0])\n",
    "tz_utc = datetime.timezone.utc\n",
    "for start_time, end_time in consecutive_periods:\n",
    "    count_list = []\n",
    "    date_list = []\n",
    "    for utc in range(int(start_time.timestamp()), int(end_time.timestamp())+1):\n",
    "        date_list.append(datetime.datetime.fromtimestamp(utc, tz=tz_utc))\n",
    "        count_list.append(cps_spec[channel][utc])\n",
    "    plt.step(date_list, count_list, where='pre', linewidth=0.5, color='red')\n",
    "\n",
    "\n",
    "# tte\n",
    "utc_list = list(cps_tte[channel].keys())\n",
    "for i in range(len(utc_list)):\n",
    "    if utc_list[i] < 1e8:\n",
    "        utc_list[i] = np.nan\n",
    "\n",
    "consecutive_periods = find_consecutive_time_periods(utc_list)\n",
    "save_consecutive_periods(consecutive_periods, mode='tte', base_time=utc_list[0])\n",
    "for start_time, end_time in consecutive_periods:\n",
    "    count_list = []\n",
    "    date_list = []\n",
    "    for utc in range(int(start_time.timestamp()), int(end_time.timestamp())+1):\n",
    "        date_list.append(datetime.datetime.fromtimestamp(utc, tz=tz_utc))\n",
    "        count_list.append(cps_tte[channel][utc])\n",
    "    plt.step(date_list, count_list, where='pre', linewidth=0.5, color='blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Light curves from file \\\"%s\\\"'%sci_file.split('/')[-1])\n",
    "plt.xlabel('UTC time')\n",
    "plt.ylabel('Counts per second')\n",
    "plt.yscale('log')\n",
    "plt.savefig(cps_figure_path)\n",
    "\n",
    "subfolder = os.path.join(output_lc_zm_dir, sci_file.split('/')[-1])\n",
    "if not os.path.exists(subfolder):\n",
    "    os.makedirs(subfolder)\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H: %M'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "counter = 0\n",
    "date_delta = datetime.timedelta(minutes=5)\n",
    "date_edge_delta = datetime.timedelta(seconds=10)\n",
    "while counter <= 300: # in case of too many plots\n",
    "    lower_bound = date_min + counter * date_delta\n",
    "    upper_bound = date_min + (counter + 1) * date_delta\n",
    "    plt.xlim(lower_bound - date_edge_delta, upper_bound + date_edge_delta)\n",
    "    plt.title('Light curves from file \\\"%s\\\", part %d'%(sci_file.split('/')[-1], counter + 1))\n",
    "    plt.savefig(os.path.join(subfolder, '%d.png' % (counter + 1)))\n",
    "    if upper_bound > date_max:\n",
    "        break\n",
    "    counter += 1\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制 长周期光谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for channel in range(4):\n",
    "    plt.step(bin_edges_long[:-1], total_spectrum_long[channel], where='post', label='Channel %d' % channel, linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.title('Spectra from file \\\"%s\\\"'%sci_file.split('/')[-1])\n",
    "plt.xlabel('ADC channel')\n",
    "plt.ylabel('Counts per ADC channel')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(os.path.join(output_spec_dir, sci_file.split('/')[-1] + '.png'))\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "processed_data_list = os.path.join(os.getcwd(), 'PROCESSED_FILE_LIST.txt')\n",
    "\n",
    "sci_file_list = []\n",
    "hk_file_list = []\n",
    "\n",
    "processed_file = open(processed_data_list, 'w')\n",
    "for root, dirs, files in os.walk('/data/GRIDSatFTP/11B/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.dat'):\n",
    "            sci_file_list.append(os.path.join(root, file))\n",
    "            processed_file.write(os.path.join(root, file))\n",
    "            processed_file.write('\\n')\n",
    "\n",
    "processed_file.close()\n",
    "print('/data/GRIDSatFTP/11B/JL1PT02A03_200331611_20241218025102/200331611_JL1PT02A03_20241218015223_other44.dat' in sci_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV & Vbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frame_parser import parse_frame_data, parse_frame_single, get_frame_data\n",
    "from addict import Dict\n",
    "\n",
    "xml_path = os.path.join(os.getcwd(), 'grid11b_packet.xml')\n",
    "\n",
    "data_path = '/lime/GRID/quick_look/GRID-11B/200323337_JL1PT02A03_20241122011928_tiange-splited/008_iv_166.raw'\n",
    "data_iv = Dict(parse_frame_data(data_path,xml_path,data_tag='iv_packet')[0])\n",
    "data_vbr = Dict(parse_frame_data(data_path,xml_path,data_tag='vbr_packet')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frame_parser import parse_frame_data\n",
    "import os\n",
    "from addict import Dict\n",
    "xml_path = os.path.join(os.getcwd(), 'grid11b_packet.xml')\n",
    "\n",
    "data_path = '/lime/GRID/quick_look/GRID-11B/200323337_JL1PT02A03_20241122011928_tiange-splited/001_hk_201.dat'\n",
    "data_hk = Dict(parse_frame_data(data_path,xml_path,data_tag='grid1x_hk_packet',endian='MSB')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_list = data_hk['utc_time']\n",
    "voltages_list = [data_hk['sipm_voltage0'], data_hk['sipm_voltage1'], data_hk['sipm_voltage2'], data_hk['sipm_voltage3']]\n",
    "currents_list = [data_hk['sipm_current0'], data_hk['sipm_current1'], data_hk['sipm_current2'], data_hk['sipm_current3']]\n",
    "temperatures_list = [data_hk['sipm_temp0'], data_hk['sipm_temp1'], data_hk['sipm_temp2'], data_hk['sipm_temp3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "# plot temperature\n",
    "date_rotate = 45\n",
    "\n",
    "file = data_path\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "plt.xticks(rotation=date_rotate)\n",
    "dates = [datetime.datetime.fromtimestamp(utc, tz=datetime.timezone.utc) for utc in utc_list]\n",
    "\n",
    "for channel in range(4):\n",
    "    plt.plot(dates, temperatures_list[channel], '-o', label='Channel %d' % channel, markersize=0.6, linewidth=0.3)\n",
    "plt.legend()\n",
    "plt.title('Temperature from file \\\"%s\\\"'%file.split('/')[-1])\n",
    "plt.xlabel('UTC time')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.savefig(os.path.join(output_temp_dir, file.split('/')[-1] + '.png'))\n",
    "plt.clf()\n",
    "\n",
    "# plot current\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "plt.xticks(rotation=date_rotate)\n",
    "dates = [datetime.datetime.fromtimestamp(utc, tz=datetime.timezone.utc) for utc in utc_list]\n",
    "for channel in range(4):\n",
    "    plt.plot(dates, currents_list[channel], '-o', label='Channel %d' % channel, markersize=0.6, linewidth=0.3)\n",
    "plt.legend()\n",
    "plt.title('SiPM current from file \\\"%s\\\"'%file.split('/')[-1])\n",
    "plt.xlabel('UTC time')\n",
    "plt.ylabel('Current (uA)')\n",
    "plt.savefig(os.path.join(output_cur_dir, file.split('/')[-1] + '.png'))\n",
    "plt.clf()\n",
    "\n",
    "# plot voltage\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "plt.xticks(rotation=date_rotate)\n",
    "dates = [datetime.datetime.fromtimestamp(utc, tz=datetime.timezone.utc) for utc in utc_list]\n",
    "for channel in range(4):\n",
    "    plt.plot(dates, voltages_list[channel], '-o', label='Channel %d' % channel, markersize=0.6, linewidth=0.3)\n",
    "plt.legend()\n",
    "plt.title('SiPM voltage from file \\\"%s\\\"'%file.split('/')[-1])\n",
    "plt.xlabel('UTC time')\n",
    "plt.ylabel('Voltage (mV)')\n",
    "plt.savefig(os.path.join(output_vol_dir, file.split('/')[-1] + '.png'))\n",
    "plt.clf()\n",
    "\n",
    "with open(output_log_file, 'a') as f:\n",
    "    f.write(file + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
